{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An examination of the stochastic distribution of spatial accessibility to intensive care unit (ICU) beds during the COVID-19 pandemic: a case study of the Greater Houston area of Texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Not only sufficiency but also reliability of healthcare access are closely related to the medical condition of people. Hence, investigating the uncertainty embedded in the temporal changes of inputs would be beneficial to understand their impact on spatial accessibility. However, previous studies are limited to implementing only the uncertainty of mobility, while healthcare resource availability is a significant concern during the coronavirus disease (COVID-19) pandemic. Our study examined the stochastic distribution of spatial accessibility under the uncertainties underlying the availability of intensive care unit (ICU) beds and ease of mobility in the Greater Houston area of Texas. Based on the randomized supply and mobility from their historical changes, we employed Monte-Carlo simulation to measure ICU bed accessibility with an enhanced two-step floating catchment area (E2SFCA) method. We then conducted hierarchical clustering to classify regions of adequate (sufficient and reliable) accessibility and inadequate (insufficient and unreliable) accessibility. Lastly, we investigated the relationship between the accessibility measures and the case fatality ratio of COVID-19. As result, locations of sufficient access also had reliable accessibility; downtown and outer counties respectively had adequate and inadequate accessibility. We also uncovered that a higher fatality ratio of peripheral counties might be attributed to their inadequate accessibility. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import warnings\n",
    "import utils\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import jenkspy\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract files related to inputs\n",
    "with zipfile.ZipFile('./data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data')\n",
    "# Extract precalculated results \n",
    "# with zipfile.ZipFile('./result.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./result')\n",
    "    \n",
    "data_path = pathlib.Path('./data')\n",
    "csv_path = data_path.joinpath('traffic_data', 'modified_csv')\n",
    "shp_path = data_path.joinpath('traffic_data', 'shp')\n",
    "result_path = pathlib.Path('./result')\n",
    "PROCESSOR_NUM = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Problem statement\n",
    "## 0.1. Uncertainty in supply (ICU beds) availability\n",
    "During the second COVID-19 outbreak in Texas (from May 1 to September 30, 2020), the percentage of available ICU beds in Harris County was maximized (21.3%, 344 of 1614 operational ICU beds) on May 25, 2020, and minimized (1.4%, 24 available beds) on July 15. The availability of ICU beds is closely related to the degree of supply that hospitals provide, and there is temporal uncertainty. For instance, an increase in ICU beds availability would alleviate local competition (i.e., more resources and high supply-to-demand ratio), whereas a decrease in availability would worsen it (i.e., fewer resources; low supply-to-demand ratio). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_list = ['Harris', 'Fort Bend', 'Montgomery', 'Brazoria', 'Galveston', 'Liberty', 'Waller', 'Chambers', 'Austin']\n",
    "staff_ICU = {'Harris': 1614, 'Fort Bend': 122, 'Montgomery': 174, 'Brazoria': 40, \n",
    "           'Galveston': 94, 'Liberty': 8, 'Waller': 0, 'Chambers': 1, 'Austin': 6}\n",
    "xls_file = pd.read_csv(data_path.joinpath('hospital_availability.csv'))\n",
    "\n",
    "ICU_usage = xls_file.groupby('Date').sum()\n",
    "ICU_usage['use_other'] = ICU_usage.apply(lambda x:sum(staff_ICU.values()) - (x['Avail_ICU'] + x['COV_S_ICU'] + x['COV_C_ICU']), axis=1)\n",
    "ICU_usage['use_COVID'] = ICU_usage.apply(lambda x: (x['COV_S_ICU'] + x['COV_C_ICU']), axis=1)\n",
    "ICU_usage = ICU_usage.filter(items=['use_other', 'use_COVID', 'Avail_ICU'])\n",
    "\n",
    "aval_fig = ICU_usage.plot.area(color=['#ABABAB','#fb9a99', '#1f78b4'], linewidth=1, figsize=(15, 5))\n",
    "for temp_line in aval_fig.lines:\n",
    "    temp_line.set_color('black')\n",
    "\n",
    "aval_fig.set_ylim(0, sum(staff_ICU.values()))\n",
    "aval_fig.set_xlim(0, 152)\n",
    "aval_fig.set_ylabel('ICU beds count', fontsize=24)\n",
    "aval_fig.set_xlabel('Date', fontsize=24)\n",
    "plt.xticks([0, 31, 61, 92, 123, 152], ['5/1/2020', '6/1/2020', '7/1/2020', '8/1/2020', '9/1/2020', '9/30/2020'], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(loc='lower right', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Missing histrorical usage data for Liberty and Austin counties (No Hospital in Waller county)\n",
    "# Therefore, we use the usage distribution of other counties to estimate theirs.\n",
    "aval_ratio = pd.DataFrame(index=xls_file['Date'].unique(), columns=[f'{county}' for county in county_list])\n",
    "\n",
    "for county in county_list:\n",
    "    if county in ['Harris', 'Fort Bend', 'Montgomery', 'Brazoria', 'Galveston', 'Chambers']:  \n",
    "        county_xls = xls_file.loc[xls_file['County'] == county]\n",
    "        county_xls = county_xls.set_index('Date')\n",
    "        county_xls['aval_ratio'] = county_xls.apply(lambda x: round((x['COV_S_ICU'] + x['COV_C_ICU'] + x['Avail_ICU']) / staff_ICU[county] * 100, 0), axis=1)\n",
    "        county_xls = county_xls.filter(items=['use_other', 'use_COVID', 'aval_ratio'])\n",
    "        \n",
    "        aval_ratio[county] = county_xls['aval_ratio']\n",
    "        \n",
    "    elif county in ['Liberty', 'Austin']: # ICU availability data missing in Liberty and Austin county\n",
    "        counties_xls = xls_file.groupby('Date').sum()\n",
    "        counties_xls['aval_ratio'] = counties_xls.apply(lambda x: round((x['COV_S_ICU'] + x['COV_C_ICU'] + x['Avail_ICU']) / sum(staff_ICU.values()) * 100, 0), axis=1)\n",
    "        aval_ratio[county] = counties_xls['aval_ratio']\n",
    "        \n",
    "    else: # No hospital in Waller County\n",
    "        aval_ratio[county] = 0\n",
    "        \n",
    "aval_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Uncertainty in mobility (travel speed)\n",
    "In addition, the uncertainty of mobility would change the size and shape of the service area that a facility provides. For example, high mobility during the nighttime would expand the service area of supply, whereas low mobility during the daytime would shrink it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound = pd.read_csv(csv_path.joinpath('IH10K_Beltway8_Downtown.csv'))\n",
    "inbound = inbound.set_index('Departure')\n",
    "outbound = pd.read_csv(csv_path.joinpath('IH10K_Downtown_Beltway8.csv'))\n",
    "outbound = outbound.set_index('Departure')\n",
    "\n",
    "mobility = pd.DataFrame(index=inbound.index)\n",
    "mobility['inbound'] = inbound['Average']\n",
    "mobility['outbound'] = outbound['Average']\n",
    "mobility\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.plot(mobility.index, mobility['inbound'], label='Inbound (I-10)', color='#b2df8a', linewidth=3)\n",
    "plt.plot(mobility.index, mobility['outbound'], label='Outbound (I-10)', color='#1f78b4', linewidth=3)\n",
    "plt.xticks(list(range(0, 55, 4)), [f'{h}\\n AM' for h in range(5, 13, 1)] + [f'{h}\\n PM' for h in range(1, 7, 1)], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax1.set_ylabel('Traffic speed (mph)', fontsize=24)\n",
    "ax1.set_xlabel('Hours', fontsize=24)\n",
    "ax1.set_xlim(-1, 56)\n",
    "ax1.set_ylim(0, 70)\n",
    "plt.legend(loc='upper right', fontsize='x-large')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Study Area: the Greater Houston, Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "supply = gpd.read_file(data_path.joinpath('geocoded_hospital.shp'))\n",
    "supply = supply.set_index('SupplyID')\n",
    "supply = supply.loc[supply['ADULT_ICU_'] != 0]\n",
    "\n",
    "demand = gpd.read_file(data_path.joinpath('hexagon_houston_pop.shp'))\n",
    "demand = demand.set_index('GRID_ID')\n",
    "\n",
    "boundary = gpd.read_file(data_path.joinpath('county_houston.shp'))\n",
    "boundary = boundary.set_index('NAME')\n",
    "road = gpd.read_file(data_path.joinpath('major_roads.shp'))\n",
    "\n",
    "colorBrewer = ['#eff3ff', '#bdd7e7', '#6baed6', '#3182bd', '#08519c']\n",
    "breaks = jenkspy.jenks_breaks(demand.Pop, nb_class=5)\n",
    "for idx, cls in enumerate(breaks):\n",
    "    if idx == 0:  \n",
    "        continue\n",
    "\n",
    "    temp_hxg = demand.loc[(breaks[idx-1] <= demand['Pop']) & (demand['Pop'] <= cls)]\n",
    "    if temp_hxg.shape[0] > 0:\n",
    "        temp_hxg.plot(ax=ax, color=colorBrewer[idx-1])\n",
    "\n",
    "supply.plot(ax=ax, markersize=supply['ADULT_ICU_'] * 2, color='black')\n",
    "boundary.apply(lambda x:ax.annotate(text=x.NAMELSAD.split('County')[0], xy=x.geometry.centroid.coords[0], ha='center', \n",
    "                                    fontsize=15, path_effects=[pe.withStroke(linewidth=4, foreground=\"white\")]), axis=1)\n",
    "road.plot(ax=ax, linewidth=0.5, edgecolor='k')\n",
    "boundary.boundary.plot(ax=ax, linewidth=0.5, edgecolor='k', linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analytical Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following three steps to measure spatial accessibility to ICU beds under the temporal uncertainty of supply and mobility. \n",
    "1) Calculate the probability distribution of supply and mobility, which would be used as the randomized input variables in the Monte-Carlo simulation. <br>\n",
    "2) Assess spatial accessibility to ICU beds 999 times (i.e., Monte-Carlo simulation) to investigate the impacts of the two randomized variables on the measures. The simulation provided the stochastic distribution of the measures for each location. <br>\n",
    "3) Spatial clustering was implemented to group locations based on the measures and to demonstrate which locations had sufficient and reliable accessibility.<br>\n",
    "\n",
    "<img src='./workflow.jpg' width='800'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Calculate probability distribution of supply and mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "aval_ratio['Harris'].hist(bins=[10, 15, 20, 25, 30, 35, 40, 45, 50, 55], ax=ax1, color='black', grid=False)\n",
    "plt.xticks(list(range(0, 105, 10)), fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax1.set_ylabel('Days (total = 153)', fontsize=24)\n",
    "ax1.set_xlabel('Availability (%)', fontsize=24)\n",
    "ax1.set_xlim(0, 100)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.hist(mobility['inbound'], bins=list(range(0, 75, 5)), label='Inbound', edgecolor='#b2df8a', linewidth=3, histtype='step')\n",
    "plt.hist(mobility['outbound'], bins=list(range(0, 75, 5)), label='Outbound' , edgecolor='#1f78b4', linewidth=3, histtype='step')\n",
    "plt.legend(loc='upper left', fontsize='x-large')\n",
    "ax2.set_ylabel('Frequency (total = 56)', fontsize=24)\n",
    "ax2.set_xlabel('Traffic speed (mph)', fontsize=24)\n",
    "ax2.set_xlim(0, 70)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks([0, 5, 10, 15, 20],fontsize=20)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of how many percentage of ICU beds are available\n",
    "probs = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "supply_prob = pd.DataFrame(index=county_list, columns=probs)\n",
    "for county in county_list:\n",
    "    for idx, val in enumerate(probs):\n",
    "        if idx == len(probs) - 1:\n",
    "            break\n",
    "            \n",
    "        supply_prob.loc[county, probs[idx+1]] = aval_ratio.loc[(aval_ratio[county] >= val*100) & (aval_ratio[county] < probs[idx +1]*100)].shape[0]\n",
    "    \n",
    "supply_prob = supply_prob / 153\n",
    "supply_prob = supply_prob.drop(columns=[0.0])\n",
    "\n",
    "for county in ['Liberty', 'Austin']:\n",
    "    for col in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        supply_prob.loc[county, col] = supply_prob.loc[['Harris', 'Fort Bend', 'Montgomery', \n",
    "                                                        'Brazoria', 'Galveston', 'Chambers'], col].mean(axis=0)\n",
    "\n",
    "for col in supply_prob.columns:\n",
    "    supply_prob[col] = supply_prob[col].astype(float)\n",
    "\n",
    "supply_prob = supply_prob.round(decimals=3)  \n",
    "for idx in supply_prob.index:\n",
    "    sum_prob = round(supply_prob.loc[idx].sum(), 3)\n",
    "    if sum_prob < 1:\n",
    "        supply_prob.loc[idx, 1.0] += 1 - sum_prob\n",
    "        \n",
    "    elif sum_prob > 1:\n",
    "        supply_prob.loc[idx, 0.2] -= sum_prob - 1\n",
    "\n",
    "supply_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Monte-Carlo simulation of spatial accessibility measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import mobility-related files\n",
    "file_names = pd.read_csv(data_path.joinpath('traffic_data', 'file_names.txt'), header=None)\n",
    "original_nodes = gpd.read_file(data_path.joinpath('osm_network_greater_houston', 'nodes.shp'))\n",
    "merged_edge = utils.road_network_with_uncertainty(file_names, data_path)\n",
    "merged_edge = merged_edge.set_crs(epsg=4326)\n",
    "G = utils.construct_network(merged_edge, original_nodes)\n",
    "G = utils.remove_uncenessary_nodes(G)\n",
    "\n",
    "# Find nearest node of OSM from supply and demand locations\n",
    "supply = utils.find_nearest_osm(G, supply)\n",
    "demand = utils.find_nearest_osm(G, demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell demonstrates only six-iteration of accessibility measurements out of 999 iterations \n",
    "to demonstrate how the Monte-Carlo simulation works. If you want to increase the iteration count to 999, \n",
    "change `range(PROCESSOR_NUM)` to `range(999)`. This change will introduce a severe computational intensity \n",
    "and would take a couple of months to finish the measurements.\n",
    "'''\n",
    "\n",
    "# Set threshold travel time and corresponding spatial impedance\n",
    "minutes = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 60]\n",
    "weights = {0: 1, 5: 0.9459, 10: 0.7544, 15: 0.5511, 20: 0.3993, 25: 0.2957, 30: 0.2253, \n",
    "           35: 0.1765, 40: 0.1417, 45: 0.1161, 60: 0.0832}\n",
    "\n",
    "\n",
    "start = int(time.time())\n",
    "pool = mp.Pool(processes = PROCESSOR_NUM)\n",
    "access_result = pool.map(utils.measure_accessibility_unpacker,\n",
    "                         zip(range(PROCESSOR_NUM),\n",
    "                             itertools.repeat(supply),\n",
    "                             itertools.repeat(demand),\n",
    "                             itertools.repeat(supply_prob),\n",
    "                             itertools.repeat(file_names),\n",
    "                             itertools.repeat(original_nodes),\n",
    "                             itertools.repeat(minutes),\n",
    "                             itertools.repeat(weights),\n",
    "                             itertools.repeat(data_path),\n",
    "                             itertools.repeat(result_path)\n",
    "                            )\n",
    "                        )\n",
    "end = int(time.time())\n",
    "pool.close()\n",
    "print(\"***run time(min) : \", (end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_cls = [0, 5, 10, 15, 20, 25]\n",
    "colors = ['#edf8e9', '#bae4b3', '#74c476', '#31a354', '#006d2c']\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i in range(PROCESSOR_NUM):\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    temp_result = gpd.read_file(result_path.joinpath (f'iter_{i}', 'demand.geojson'))\n",
    "    \n",
    "    for idx, cls in enumerate(plt_cls):\n",
    "        if idx == 0: continue\n",
    "        temp_cls = temp_result.loc[(plt_cls[idx-1] < temp_result[f'step2']) & (temp_result[f'step2'] <= cls)]\n",
    "        if temp_cls.shape[0] > 0:\n",
    "            temp_cls.plot(ax=ax, color=colors[idx-1], edgecolor=colors[idx-1])\n",
    "            \n",
    "    boundary.apply(lambda x:ax.annotate(text=x.NAMELSAD.split('C')[0], xy=x.geometry.centroid.coords[0], ha='center', \n",
    "                                    fontsize=12, path_effects=[pe.withStroke(linewidth=4, foreground=\"white\")]), axis=1)\n",
    "    \n",
    "    road.plot(ax=ax, linewidth=0.5, edgecolor='k')\n",
    "    boundary.boundary.plot(ax=ax, linewidth=0.5, edgecolor='k', linestyle=':')\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Spatial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the precalculated result for the demonstration purpose\n",
    "measures = gpd.read_file(result_path.joinpath(r'precalculated_measures.shp'))\n",
    "measures = measures.loc[measures['Note'] != 'water']\n",
    "measures = measures.fillna(0)\n",
    "measures = measures.set_index('GRID_ID')\n",
    "measures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics of the monte-carlo simulation result\n",
    "measures['p05'] = measures[[f'n_{i}' for i in range(1, 1000)]].quantile(0.95, axis=1)\n",
    "measures['p25'] = measures[[f'n_{i}' for i in range(1, 1000)]].quantile(0.75, axis=1)\n",
    "measures['p50'] = measures[[f'n_{i}' for i in range(1, 1000)]].quantile(0.50, axis=1)\n",
    "measures['p75'] = measures[[f'n_{i}' for i in range(1, 1000)]].quantile(0.25, axis=1)\n",
    "measures['p95'] = measures[[f'n_{i}' for i in range(1, 1000)]].quantile(0.05, axis=1)\n",
    "\n",
    "measures['mean'] = measures[[f'n_{i}' for i in range(1, 1000)]].mean(axis=1)\n",
    "measures['std'] = measures[[f'n_{i}' for i in range(1, 1000)]].std(axis=1)\n",
    "measures['cv'] = measures['std'] / measures['mean']\n",
    "measures = measures.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#eff3ff', '#bdd7e7', '#6baed6', '#3182bd', '#08519c']\n",
    "plt_cls = [0, 5, 10, 15, 20, 25]\n",
    "good_acc_value = 10\n",
    "hxg_plot = ['Z-19','AX-27', 'AT-33', 'BK-46']\n",
    "hxg_colors = ['#377eb8', '#4daf4a', '#e41a1c', '#ff7f00']\n",
    "\n",
    "fig = plt.figure(figsize=(20, 18))\n",
    "outer = gridspec.GridSpec(2, 2, wspace=0.05, hspace=0.15)\n",
    "for idx, ratio in enumerate(['p50', 'p05', 'p95']):\n",
    "    ax = plt.Subplot(fig, outer[idx+1])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    for idx, cls in enumerate(plt_cls):\n",
    "        if idx == 0: continue\n",
    "        temp_hxg = measures.loc[(plt_cls[idx-1] < measures[f'{ratio}']) & (measures[f'{ratio}'] <= cls)]\n",
    "        if temp_hxg.shape[0] > 0:\n",
    "            temp_hxg.plot(ax=ax, color=colors[idx-1], edgecolor=colors[idx-1])\n",
    "        ax.text(0.95, 0.95, str(ratio), fontsize=30, ha='right', va='top', transform=ax.transAxes)\n",
    "    \n",
    "    good_acc = measures.loc[measures[f'{ratio}'] >= good_acc_value]\n",
    "    good_acc['dummy'] = 'dummy'\n",
    "    good_acc.dissolve(by='dummy').boundary.plot(ax=ax, color=None, edgecolor='blue', linewidth=2)\n",
    "    ax.text(0.95, 0.05, str(good_acc.shape[0]), fontsize=30, ha='right', va='bottom', transform=ax.transAxes)\n",
    "    \n",
    "    # supplementary poi\n",
    "    boundary.apply(lambda x:ax.annotate(text=x.NAMELSAD.split('C')[0], xy=x.geometry.centroid.coords[0], ha='center', \n",
    "                                        fontsize=15, path_effects=[pe.withStroke(linewidth=4, foreground=\"white\")]), axis=1)\n",
    "    road.plot(ax=ax, linewidth=0.5, edgecolor='k')\n",
    "    boundary.boundary.plot(ax=ax, linewidth=1, edgecolor='k', linestyle=':')\n",
    "    fig.add_subplot(ax)\n",
    "    \n",
    "    if ratio == 'p50':\n",
    "        for idx_2, hxg in enumerate(hxg_plot):\n",
    "            measures.loc[measures.index == hxg].plot(color=hxg_colors[idx_2], ax=ax)\n",
    "            measures.loc[measures.index == hxg].centroid.plot(color=hxg_colors[idx_2], ax=ax, linewidth=10, zorder=2)\n",
    "            print(hxg, measures.loc[measures.index == hxg]['mean'].values[0], measures.loc[measures.index == hxg]['std'].values[0])\n",
    "                \n",
    "        inner = gridspec.GridSpecFromSubplotSpec(4, 1,\n",
    "                subplot_spec=outer[0], wspace=0.1, hspace=0.2)\n",
    "        # Histogram\n",
    "        for idx_1, hxg in enumerate(hxg_plot):\n",
    "            ax1 = plt.Subplot(fig, inner[idx_1])\n",
    "            temp_df = measures.loc[hxg, [f'n_{num}' for num in range(1, 1000)]]\n",
    "            bins = round((temp_df.max() - temp_df.min()) / 0.5)\n",
    "            temp_df.hist(ax=ax1, color=hxg_colors[idx_1], bins=bins)\n",
    "\n",
    "            ax1.set_xlim(0, 25)\n",
    "            ax1.set_ylim(0, 300)\n",
    "            ax1.set_yticks([0, 100, 200, 300])\n",
    "            ax1.tick_params(axis='both', labelsize=20)\n",
    "            ax1.grid(True)\n",
    "            \n",
    "            if idx_1 != 3:\n",
    "                plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "                ax1.tick_params(axis='x', which='both', length=0)\n",
    "            else:\n",
    "                ax1.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "                ax1.set_xlabel('Accessiblity Measures', fontsize=25)\n",
    "            fig.add_subplot(ax1)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['#80cdc1', '#dfc27d', '#c7eae5', '#a6611a', '#01665e']\n",
    "\n",
    "m_acc = measures[[f'n_{i}' for i in range(1, 1000)]]  # Only columns of values\n",
    "m_acc = m_acc.fillna(0)\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters = 5, linkage='ward').fit(m_acc)\n",
    "measures['cluster'] = clustering.labels_\n",
    "print('Number of Hexagons', '|',  'color hex code','|',  'Population', '|', 'Min Acc, Mean Acc, Max Acc', '|', 'Mean CV')\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i in range(5):    \n",
    "    tt = measures.loc[measures['cluster'] == i]\n",
    "    print(tt.shape[0], '|', color_list[i],'|',  tt['Pop'].sum(), '|', round(tt['mean'].min(),3), round(tt['mean'].mean(),3), round(tt['mean'].max(),3), '|',round(tt['cv'].mean(), 3))\n",
    "    tt.plot(ax=ax, color=color_list[i], edgecolor=color_list[i])\n",
    "    tt.dissolve('cluster').boundary.plot(color='black', ax=ax, linewidth=0.5)\n",
    "        \n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# supplementary poi\n",
    "boundary.apply(lambda x:ax.annotate(text=x.NAMELSAD.split('C')[0], xy=x.geometry.centroid.coords[0], ha='center', \n",
    "                                    fontsize=18, path_effects=[pe.withStroke(linewidth=4, foreground=\"white\")]), axis=1)\n",
    "road.plot(ax=ax, linewidth=1, edgecolor='k')\n",
    "boundary.boundary.plot(ax=ax, linewidth=1, edgecolor='k', linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "list_silhouette = []\n",
    "for i in range(2, 11):\n",
    "    cluster_labels = hierarchy.cut_tree(hierarchy.ward(m_acc), n_clusters=i).T[0]\n",
    "    list_silhouette.append(round(silhouette_score(m_acc, cluster_labels), 4))\n",
    "    print(i, round(silhouette_score(m_acc, cluster_labels), 4), cluster_labels)\n",
    "    \n",
    "plt.plot(range(2, 11), list_silhouette, color='black', linewidth='3', marker='o', linestyle='solid')\n",
    "plt.xticks(list(range(0, 11, 1)), fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "ax.set_xlabel('Number of clusters', fontsize=20)\n",
    "ax.set_ylabel('Silhouette coefficients', fontsize=20)\n",
    "ax.set_xlim(xmin=1)\n",
    "ax.set_ylim(ymin=0.4, ymax= 0.65)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_measures = measures.reset_index()\n",
    "\n",
    "Z = hierarchy.linkage(m_acc.to_numpy(), 'ward')\n",
    "dn = hierarchy.dendrogram(Z, labels=measures.index.to_list(), no_plot=True)\n",
    "\n",
    "D_leaf_colors = {}\n",
    "for leaf_idx in dn['leaves']:\n",
    "    leaf_cluster = temp_measures.loc[leaf_idx, 'cluster']\n",
    "    D_leaf_colors[leaf_idx] = color_list[leaf_cluster]\n",
    "\n",
    "dflt_col = \"#808080\" \n",
    "link_cols = {}\n",
    "for i, i12 in enumerate(Z[:,:2].astype(int)):\n",
    "    c1, c2 = (link_cols[x] if x > len(Z) else D_leaf_colors[x] for x in i12)\n",
    "    link_cols[i+1+len(Z)] = c1 if c1 == c2 else dflt_col\n",
    "    \n",
    "plt.figure(figsize=(10,4))\n",
    "D = hierarchy.dendrogram(Z=Z, link_color_func=lambda x: link_cols[x], no_labels=True)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i in range(5):\n",
    "    tt = measures.loc[measures['cluster'] == i]\n",
    "    plt.scatter(tt['mean'].values, tt['cv'], s=5, color=color_list[i])\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "ax.set_xlim(xmin=0)\n",
    "ax.set_ylim(ymin=0, ymax=1)\n",
    "ax.set_xlabel('Mean', fontsize=20)\n",
    "ax.set_ylabel('Coefficient of variation', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('mean_cv_1.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Relationship between accessibility and case-fatality ratio\n",
    "We observed a trend where the case fatality ratio of COVID-19 can be attributed to unsatisfactory accessibility even though it may not be statistically significant because of the limited number of samples (n = 9 counties). Three of nine counties showed a higher case fatality rate than the average in the study area. While 18‰ (18 fatalities per 1,000 people) of the case fatality rate was observed as of September 30, 2020, Liberty, Austin, and Harris counties had case fatality rates of 23‰, 20‰, and 19‰, respectively. Liberty and Austin counties had insufficient (mean accessibility: 2.09 and 1.64) and unreliable (mean CV of accessibility: 0.13 and 0.27) accessibility. Therefore, their high rates can be related to the attributes of their accessibility. However, Harris County had a robust accessibility (mean accessibility: 10.39, and mean CV: 0.07). Its casualty could be caused by the intensive transmission of the virus within a short period, which was often reported in a high-density city such as New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate case-fatality ratio of each county until September 30, 2020.\n",
    "case = pd.read_excel(data_path.joinpath('covid_case.xlsx'), header=2, index_col='County Name')\n",
    "case_texas = case.loc['Total','Cases 09-30-2020']\n",
    "case_study_area = case.loc[['Harris', 'Fort Bend', 'Montgomery', 'Brazoria', 'Galveston', 'Liberty', 'Waller', 'Chambers', 'Austin'], 'Cases 09-30-2020']\n",
    "case_study_area.index = case_study_area.index.str.lower()\n",
    "\n",
    "death = pd.read_excel(data_path.joinpath('covid_fatality.xlsx'), header=2, index_col='County Name')\n",
    "death_texas = death.loc['Total', 'Fatalities 09-30-2020']\n",
    "death_study_area = death.loc[['Harris'.upper(), 'Fort Bend'.upper(), 'Montgomery'.upper(), 'Brazoria'.upper(), 'Galveston'.upper(), 'Liberty'.upper(), 'Waller'.upper(), 'Chambers'.upper(), 'Austin'.upper()], 'Fatalities 09-30-2020']\n",
    "death_study_area.index = death_study_area.index.str.lower()\n",
    "\n",
    "death_ratio = pd.DataFrame({'case': case_study_area, 'death': death_study_area})\n",
    "death_ratio['ratio'] = death_ratio['death'] / death_ratio['case'] * 1000\n",
    "death_ratio_texas = death_texas / case_texas\n",
    "death_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and coefficient of variance of accessibility to ICU beds per each county\n",
    "measures.loc[measures['cv'] > 1, 'cv'] = 1\n",
    "\n",
    "death_ratio['acc_mean'] = 0.0\n",
    "death_ratio['acc_cv'] = 0.0\n",
    "\n",
    "for idx, row in boundary.iterrows():\n",
    "    temp_mean = measures.loc[measures.geometry.intersects(row.geometry),  'mean'].mean()\n",
    "    temp_cv = measures.loc[measures.geometry.intersects(row.geometry),  'cv'].mean()\n",
    "    \n",
    "    county_name = idx.lower()\n",
    "    \n",
    "    death_ratio.at[county_name, 'acc_mean'] = temp_mean\n",
    "    death_ratio.at[county_name, 'acc_cv'] = temp_cv\n",
    "    \n",
    "death_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study_area_ratio = death_ratio.death.sum()/death_ratio.case.sum()*1000\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "ax.scatter(death_ratio['acc_mean'], death_ratio.acc_cv, death_ratio.ratio**2.5, color='black')\n",
    "ax.scatter(9, 0.4, study_area_ratio**2.5)  # total case-fatality ratio of the study area\n",
    "ax.text(x=8.2, y=0.415,  s='Reference: average case-fatality \\n                  ratio of the study area', fontsize=12)\n",
    "\n",
    "ax.set_xlim(xmin=0, xmax=12)\n",
    "ax.set_ylim(ymin=0, ymax=0.5)\n",
    "ax.set_xlabel('Averaged accessibility of each county', fontsize=24)\n",
    "ax.set_ylabel('Averaged CV of each county', fontsize=24)\n",
    "\n",
    "for idx, row in death_ratio.iterrows():\n",
    "    ax.text(x=row['acc_mean'], y=row['acc_cv'], s=idx, rotation=15, fontsize=15, path_effects=[pe.withStroke(linewidth=8, foreground=\"white\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(list_of_values):\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    return (fair_area - area) / fair_area\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8,8])\n",
    "\n",
    "plot_colors = ['#377eb8', '#e41a1c', '#ff7f00']\n",
    "for idx, ratio in enumerate(['p05', 'p50', 'p95']):\n",
    "    X = measures[f'{ratio}'].to_numpy(copy=True)\n",
    "    X.sort()\n",
    "    \n",
    "    print(gini(X))\n",
    "    \n",
    "    X_lorenz = X.cumsum() / X.sum()\n",
    "    X_lorenz = np.insert(X_lorenz, 0, 0)\n",
    "    X_lorenz[0], X_lorenz[-1]\n",
    "\n",
    "    ## scatter plot of Lorenz curve\n",
    "    ax.scatter(np.arange(X_lorenz.size)/(X_lorenz.size-1), X_lorenz, \n",
    "               marker='.', s=1, label=ratio, color=plot_colors[idx])\n",
    "    ## line plot of equality\n",
    "    ax.plot([0,1], [0,1], color='k')\n",
    "    \n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax.set_xlim(xmin=0, xmax=1)\n",
    "ax.set_ylim(ymin=0, ymax=1)\n",
    "ax.set_ylabel('Cumulative proportion of accessibility', fontsize=24)\n",
    "ax.set_xlabel('Cumulative proportion of hexagons', fontsize=24)\n",
    "plt.legend(fontsize='xx-large')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
